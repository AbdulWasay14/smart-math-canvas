{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"gjuHYh5OUwdW"},"outputs":[],"source":["!unzip /content/drive/MyDrive/aircanvas_project/archive.zip\n"]},{"cell_type":"code","source":["!pip install imutils\n","\n","import numpy as np \n","import pandas as pd \n","import cv2\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from imutils.contours import sort_contours\n","import imutils"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fLvSsecnVScP","executionInfo":{"status":"ok","timestamp":1683012214483,"user_tz":-300,"elapsed":9529,"user":{"displayName":"k200211 Mubin","userId":"05650803725135824586"}},"outputId":"8f07681e-ef84-4390-d58e-dabdb4b9d4e1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: imutils in /usr/local/lib/python3.10/dist-packages (0.5.4)\n"]}]},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import Conv2D\n","from keras.layers import MaxPooling2D\n","from keras.layers import Dense\n","from keras.layers import Flatten\n","from keras.optimizers import SGD\n","from keras.preprocessing.image import ImageDataGenerator\n","import os"],"metadata":{"id":"it2DO5nIVia2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_datagen = ImageDataGenerator(\n","    rescale = 1./255, \n","    shear_range = 0.2, \n","    zoom_range = 0.2,\n","    validation_split = 0.25\n",")\n","\n","data_path='/content/CompleteImages/All data (Compressed)'\n","train_set = train_datagen.flow_from_directory(\n","    data_path, \n","    target_size = (40, 40), \n","    color_mode = 'grayscale',\n","    batch_size = 32,\n","    class_mode = 'categorical',\n","    shuffle = True,\n","    subset='training',\n","    seed = 123\n",")\n","valid_set = train_datagen.flow_from_directory(\n","    data_path, \n","    target_size = (40, 40), \n","    color_mode = 'grayscale',\n","    batch_size = 32,\n","    class_mode = 'categorical',\n","    shuffle = True,\n","    subset='validation',\n","    seed = 123\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mjsvnbl6VkYH","executionInfo":{"status":"ok","timestamp":1683012243196,"user_tz":-300,"elapsed":12115,"user":{"displayName":"k200211 Mubin","userId":"05650803725135824586"}},"outputId":"9a1fb9ee-d374-45e4-a23c-4a5b46f7d30b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 250428 images belonging to 16 classes.\n","Found 83467 images belonging to 16 classes.\n"]}]},{"cell_type":"code","source":["model = Sequential()\n","model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(40, 40, 1)))\n","model.add(MaxPooling2D((2, 2)))\n","model.add(Conv2D(64, (3, 3), activation='relu'))\n","model.add(MaxPooling2D((2, 2)))\n","model.add(Flatten())\n","model.add(Dense(128, activation='relu'))\n","model.add(Dense(16, activation='softmax'))\n","# compile model\n","adam = tf.keras.optimizers.Adam(learning_rate = 5e-4)\n","model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])"],"metadata":{"id":"--WMZhB3VmQG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.fit(train_set,validation_data=valid_set,epochs=2, verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kdyprpW7Vn8o","executionInfo":{"status":"ok","timestamp":1683013984990,"user_tz":-300,"elapsed":1707259,"user":{"displayName":"k200211 Mubin","userId":"05650803725135824586"}},"outputId":"97ec6de4-679d-4b9f-9e9f-bf5937331f87"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","7826/7826 [==============================] - 849s 108ms/step - loss: 0.3689 - accuracy: 0.8837 - val_loss: 0.3174 - val_accuracy: 0.9058\n","Epoch 2/2\n","7826/7826 [==============================] - 847s 108ms/step - loss: 0.1795 - accuracy: 0.9415 - val_loss: 0.2665 - val_accuracy: 0.9192\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f5efc6057e0>"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["model.save_weights('/content/drive/MyDrive/aircanvas_project/my_model_weights.h5')\n","with open('/content/drive/MyDrive/aircanvas_project/my_model_architecture.json', 'w') as f:\n","    f.write(model.to_json())\n"],"metadata":{"id":"VIHTUXNKVzHp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"BMBI9D4Nc3mk"},"execution_count":null,"outputs":[]}]}